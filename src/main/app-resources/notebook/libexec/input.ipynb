{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Sentinel-1 offset tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This application takes a pair of Sentinel-1 products and identifies and generates the coherence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <a name=\"quicklink\">Quick link\n",
    "\n",
    "* [Objective](#objective)\n",
    "* [Test Site](#test-site)\n",
    "* [Context](#context)\n",
    "* [Applicability](#applicability)\n",
    "* [Data](#data)\n",
    "* [Service Definition](#service)\n",
    "* [Parameter Definition](#parameter)\n",
    "* [Runtime Parameter Definition](#runtime)\n",
    "* [Workflow](#workflow)\n",
    "* [Strengths and Limitations](#strengths-limitations) \n",
    "* [License](#license)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As a data processor developer, I want to implement, and package an algorithm processing a pair of S1 SAR SLC datasets using the SNAP toolbox notebook archetype with the following processing steps:\n",
    "\n",
    "A. S1 SAR processing per image:\n",
    "\n",
    "* Application of orbit file (should wait for the orbit file a couple of days, since for coherence this is important)\n",
    "* TOPS slice assembly (if necessary)\n",
    "* TOPS split (if necessary)\n",
    "\n",
    "B. For image pair:\n",
    "\n",
    "* TOPS coregistration\n",
    "* Coherence estimation (Given set of images from same orbit,  {t1, t2, t3, ... , tn}, two temporally adjacent images would * constitute an image pair, with the first one being the master. So the pairs would be: {t1 - t2, t2 - t3, ... , tn-1 - tn}.)\n",
    "* TOPS deburst\n",
    "* Multi-looking\n",
    "* Terrain correction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TOPS --> Terrain Observation by Prograssive Scans\n",
    "\n",
    "TOPS Slice assembly-->assemble subswaths back together\n",
    "\n",
    "TOPS split -->split into subswaths\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"service\">Service definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "service = dict([('title', 'Sentinel-1 offset tracking'),\n",
    "                ('abstract', 'Sentinel-1 offset tracking'),\n",
    "                ('id', 'offset-tracking')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_velocity = dict([('id', 'max_velocity'),\n",
    "               ('value', '8'),\n",
    "               ('title', 'Max velocity'),\n",
    "               ('abstract', 'Max velocity (m/day)')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarisation = dict([('id', 'polarisation'),\n",
    "                     ('value', 'VV'),\n",
    "                     ('title', 'Polarisation'),\n",
    "                     ('abstract', 'Polarisation')])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 8,
>>>>>>> 860475dd5119768efc22c4f19be958bcce59e9a0
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi_wkt = dict([('id', 'area_of_interest'),\n",
<<<<<<< HEAD
    "                     ('value', 'POLYGON ((119.46 -0.8,119.46 -0.412,120.3 -0.412,120.3 -0.8,119.46 -0.8))'),\n",
=======
    "                     ('value', 'POLYGON ((120.234 -1.823, 120.234 -0.5600000000000001, 119.52 -0.5600000000000001, 119.52 -1.823, 120.234 -1.823))'),\n",
>>>>>>> 860475dd5119768efc22c4f19be958bcce59e9a0
    "                     ('title', 'Area of interest in WKT'),\n",
    "                     ('abstract', 'Area of interest in WKT')])"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bbox = dict([('id', 'bbox'),\n",
    "#            ('value', 'POLYGON((172.573 -43.021,172.573 -41.55,174.298 -41.55,174.298 -43.021,172.573 -43.021))'),\n",
    "#            ('title', 'AOI'),\n",
    "#            ('abstract', 'AOI')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
=======
>>>>>>> 860475dd5119768efc22c4f19be958bcce59e9a0
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"runtime\">Runtime parameter definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input identifiers**\n",
    "\n",
    "These are the Sentinel-1 product identifiers"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 9,
>>>>>>> 860475dd5119768efc22c4f19be958bcce59e9a0
   "metadata": {},
   "outputs": [],
   "source": [
    "input_identifiers = ('S1A_IW_GRDH_1SDV_20181005T214239_20181005T214304_024006_029F71_16D6', \n",
    "                     'S1A_IW_GRDH_1SDV_20181005T214304_20181005T214335_024006_029F71_C8C4',\n",
    "                     'S1A_IW_GRDH_1SDV_20180607T214243_20180607T214308_022256_026888_8C77',\n",
    "                     'S1A_IW_GRDH_1SDV_20180607T214218_20180607T214243_022256_026888_C1E1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_identifiers = ('S1A_IW_SLC__1SDV_20161115T072242_20161115T072310_013949_016775_F621',\n",
    "#                     'S1A_IW_SLC__1SSV_20161103T072248_20161103T072317_013774_0161F9_E78A',\n",
    "#                     'S1A_IW_SLC__1SSV_20161103T072220_20161103T072250_013774_0161F9_2F68',\n",
    "#                     'S1A_IW_SLC__1SDV_20161115T072214_20161115T072244_013949_016775_84CF')\n",
    "                     #'S1A_IW_SLC__1SSV_20161103T072248_20161103T072317_013774_0161F9_E78A',\n",
    "                     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input references**\n",
    "\n",
    "These are the Sentinel-1 catalogue references"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": 10,
>>>>>>> 860475dd5119768efc22c4f19be958bcce59e9a0
   "metadata": {},
   "outputs": [],
   "source": [
    "input_references = ('https://catalog.terradue.com/sentinel1/search?format=atom&uid=S1A_IW_GRDH_1SDV_20181005T214239_20181005T214304_024006_029F71_16D6', \n",
    "                    'https://catalog.terradue.com/sentinel1/search?format=atom&uid=S1A_IW_GRDH_1SDV_20181005T214304_20181005T214335_024006_029F71_C8C4',\n",
    "                    'https://catalog.terradue.com/sentinel1/search?format=atom&uid=S1A_IW_GRDH_1SDV_20180607T214243_20180607T214308_022256_026888_8C77',\n",
    "                    'https://catalog.terradue.com/sentinel1/search?format=atom&uid=S1A_IW_GRDH_1SDV_20180607T214218_20180607T214243_022256_026888_C1E1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_references = ('https://catalog.terradue.com/sentinel1/search?format=json&uid=S1A_IW_SLC__1SDV_20161115T072242_20161115T072310_013949_016775_F621',\n",
    "#                    'https://catalog.terradue.com/sentinel1/search?format=json&uid=S1A_IW_SLC__1SSV_20161103T072248_20161103T072317_013774_0161F9_E78A',\n",
    "#                    'https://catalog.terradue.com/sentinel1/search?format=json&uid=S1A_IW_SLC__1SSV_20161103T072220_20161103T072250_013774_0161F9_2F68',\n",
    "#                    'https://catalog.terradue.com/sentinel1/search?format=json&uid=S1A_IW_SLC__1SDV_20161115T072214_20161115T072244_013949_016775_84CF')\n",
    "                    #'https://catalog.terradue.com/sentinel1/search?format=json&uid=S1A_IW_SLC__1SSV_20161103T072248_20161103T072317_013774_0161F9_E78A',\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Data path**\n",
    "\n",
    "This path defines where the data is staged-in. "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": 11,
>>>>>>> 860475dd5119768efc22c4f19be958bcce59e9a0
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = '/workspace/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"workflow\">Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the packages required for processing the data"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": 12,
>>>>>>> 860475dd5119768efc22c4f19be958bcce59e9a0
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('/application/notebook/libexec/') \n",
    "sys.path.append(os.getcwd())\n",
    "import ellip_snap_helpers\n",
    "import xml.etree.ElementTree as ET\n",
    "from scipy import interpolate\n",
    "from snappy import jpy\n",
    "from snappy import ProductIO\n",
    "from snappy import GPF\n",
    "from snappy import HashMap\n",
    "\n",
    "import dateutil.parser as parser\n",
    "import gc\n",
    "import geopandas as gpd\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gzip\n",
    "import shutil\n",
    "import csv \n",
    "import gdal\n",
    "import osr\n",
    "import math \n",
    "import lxml.etree as etree\n",
    "\n",
    "from shapely.wkt import loads\n",
    "from shapely.geometry import mapping\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from shapely.geometry import box\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import glob\n",
    "\n",
    "sys.path.append('/opt/anaconda/bin/')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "\n",
    "from osgeo.gdalconst import GA_ReadOnly\n",
    "from struct import unpack\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "import cioppy\n",
    "ciop = cioppy.Cioppy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check if all the products have the same track number"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": 13,
>>>>>>> 860475dd5119768efc22c4f19be958bcce59e9a0
   "metadata": {},
   "outputs": [],
   "source": [
    "product_TR = [None]*len(input_references)\n",
    "\n",
    "for index,product_ref in enumerate(input_references):\n",
    "    \n",
    "    result_prod = ciop.search(end_point=product_ref,\n",
    "                              params=[],\n",
    "                              output_fields='startdate,track',\n",
    "                              model='EOP')\n",
    "    \n",
    "    product_TR[index] = result_prod[0]['track']\n",
    "    \n",
    "    if index==0:\n",
    "        \n",
    "        slave_date = result_prod[0]['startdate'][:10]\n",
    "    \n",
    "    elif result_prod[0]['startdate'][:10] > slave_date:\n",
    "    \n",
    "        slave_date = result_prod[0]['startdate'][:10]\n",
    "\n",
    "if not all(x == product_TR[0] for x in product_TR):\n",
    "\n",
    "    raise ValueError('Not all products pertain the same track !')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
=======
   "execution_count": 14,
>>>>>>> 860475dd5119768efc22c4f19be958bcce59e9a0
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2018-10-05'"
      ]
     },
<<<<<<< HEAD
     "execution_count": 13,
=======
     "execution_count": 14,
>>>>>>> 860475dd5119768efc22c4f19be958bcce59e9a0
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slave_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the products"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 304,
=======
   "execution_count": 15,
>>>>>>> 860475dd5119768efc22c4f19be958bcce59e9a0
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S1A_IW_GRDH_1SDV_20181005T214239_20181005T214304_024006_029F71_16D6"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 's1prd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-304-457a016efadc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0ms1prd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms1_meta_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0;32mprint\u001b[0m \u001b[0midentifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms1prd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProductIO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetProductReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SENTINEL-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mproduct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadProductNodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms1prd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 's1prd' is not defined"
     ]
    }
   ],
   "source": [
    "s1meta = \"manifest.safe\"\n",
    "\n",
    "#slave_date = ''\n",
    "\n",
    "slave_products = []\n",
    "master_products = []\n",
    "\n",
    "slave_prefix = []\n",
    "master_prefix = []\n",
    "\n",
    "dates = []\n",
    "\n",
    "for index, identifier in enumerate(input_identifiers):\n",
    "\n",
    "    \n",
    "    s1_zip_file = os.path.join(data_path, identifier + '.zip') \n",
    "    s1_meta_file = os.path.join(data_path, identifier + '.SAFE', 'manifest.safe') \n",
    "\n",
    "    if os.path.isfile(s1_zip_file):\n",
    "        s1prd = s1_zip_file\n",
    "    elif os.path.isfile(s1_meta_file):\n",
    "        s1prd = s1_meta_file\n",
    "\n",
    "    print identifier, s1prd\n",
    "    reader = ProductIO.getProductReader(\"SENTINEL-1\")\n",
    "    product = reader.readProductNodes(s1prd, None)\n",
    "    \n",
    "    \n",
    "    width = product.getSceneRasterWidth()\n",
    "    height = product.getSceneRasterHeight()\n",
    "    name = product.getName()\n",
    "    start_date = parser.parse(product.getStartTime().toString()).isoformat()\n",
    "    \n",
    "    dates.append(start_date[:19])\n",
    "\n",
    "    if start_date[:10] == slave_date:\n",
    "        \n",
    "            slave_products.append(s1prd)\n",
    "            print(\"\\nProduct: %s, %d x %d pixels of %s assigned as slave\" % (name, width, height, start_date))\n",
    "            slave_prefix.append(identifier.split('_')[-1]) \n",
    "            slave_data_take = identifier.split('_')[-2]\n",
    "    else:\n",
    "            master_products.append(s1prd)\n",
    "            print(\"\\nProduct: %s, %d x %d pixels of %s assigned as master\" % (name, width, height, start_date))\n",
    "            master_data_take = identifier.split('_')[-2]  \n",
    "            master_prefix.append(identifier.split('_')[-1]) \n",
    "\n",
    "                        \n",
    "output_name = 'S1_OFFSET_TRACKING_%s_%s' % (parser.parse(min(dates)).strftime('%Y%m%d%H%M%S'),\n",
    "                                                     parser.parse(max(dates)).strftime('%Y%m%d%H%M%S'))\n",
    "\n",
    "print(\"\\nco-registered OUTPUT Img name is %s\"%output_name)\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
=======
   "execution_count": 16,
>>>>>>> 860475dd5119768efc22c4f19be958bcce59e9a0
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mygraph = ellip_snap_helpers.GraphProcessor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read and if need assemble the products"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 17,
>>>>>>> 860475dd5119768efc22c4f19be958bcce59e9a0
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Read'\n",
    "\n",
    "node_id = 'Read'\n",
    "\n",
    "source_node_id = ''"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 18,
>>>>>>> 860475dd5119768efc22c4f19be958bcce59e9a0
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(slave_products) > 1:\n",
    "  \n",
    "    slave_read_nodes = []\n",
    "    \n",
    "    # Read \n",
    "    for index, slave_identifier in enumerate(slave_products):\n",
    "        \n",
    "        operator = 'Read'\n",
    "        \n",
    "        parameters = ellip_snap_helpers.get_operator_default_parameters(operator)\n",
    "        \n",
    "        node_id = 'Read-S(%s)' % index\n",
    "        \n",
    "        source_node_id = ''\n",
    "        \n",
    "        parameters['file'] = slave_identifier\n",
    "                \n",
    "        mygraph.add_node(node_id, operator, parameters, source_node_id)\n",
    "    \n",
    "        slave_read_nodes.append(node_id)\n",
    "    \n",
    "    \n",
    "    source_nodes_id = slave_read_nodes\n",
    "        \n",
    "    operator = 'SliceAssembly'\n",
    "       \n",
    "    node_id = 'SliceAssembly-S'\n",
    "    \n",
    "    parameters = ellip_snap_helpers.get_operator_default_parameters(operator)\n",
    "    \n",
    "    parameters['selectedPolarisations'] = polarisation['value']\n",
    "    \n",
    "    mygraph.add_node(node_id, operator, parameters, source_nodes_id)\n",
    "\n",
    "    source_slave_orbit = node_id\n",
    "    \n",
    "else:\n",
    "    \n",
    "    operator = 'Read'\n",
    "        \n",
    "    parameters = ellip_snap_helpers.get_operator_default_parameters(operator)\n",
    "        \n",
    "    node_id = 'Read-S'\n",
    "        \n",
    "    source_node_id = ''\n",
    "        \n",
    "    parameters['file'] = slave_products[0]\n",
    "        \n",
    "    mygraph.add_node(node_id, operator, parameters, source_node_id)\n",
    "    \n",
    "source_slave_orbit = node_id"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 19,
>>>>>>> 860475dd5119768efc22c4f19be958bcce59e9a0
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(master_products) > 1:\n",
    "  \n",
    "    master_read_nodes = []\n",
    "    \n",
    "    # Read \n",
    "    for index, master_identifer in enumerate(master_products):\n",
    "        \n",
    "        operator = 'Read'\n",
    "        \n",
    "        parameters = ellip_snap_helpers.get_operator_default_parameters(operator)\n",
    "        \n",
    "        node_id = 'Read-M(%s)' % index\n",
    "        \n",
    "        source_node_id = ''\n",
    "        \n",
    "        parameters['file'] = master_identifer\n",
    "        \n",
    "        mygraph.add_node(node_id, operator, parameters, source_node_id)\n",
    "    \n",
    "        master_read_nodes.append(node_id)\n",
    "    \n",
    "    \n",
    "    source_nodes_id = master_read_nodes\n",
    "        \n",
    "    operator = 'SliceAssembly'\n",
    "       \n",
    "    node_id = 'SliceAssembly-M'\n",
    "    \n",
    "    parameters = ellip_snap_helpers.get_operator_default_parameters(operator)\n",
    "    \n",
    "    parameters['selectedPolarisations'] = polarisation['value']\n",
    "    \n",
    "    mygraph.add_node(node_id, operator, parameters, source_nodes_id)\n",
    "\n",
    "    source_master_orbit = node_id\n",
    "    \n",
    "else:\n",
    "    \n",
    "    operator = 'Read'\n",
    "        \n",
    "    parameters = ellip_snap_helpers.get_operator_default_parameters(operator)\n",
    "        \n",
    "    node_id = 'Read-M'\n",
    "        \n",
    "    source_node_id = ''\n",
    "        \n",
    "    parameters['file'] = master_products[0]\n",
    "        \n",
    "    mygraph.add_node(node_id, operator, parameters, source_node_id)\n",
    "    \n",
    "source_master_orbit = node_id"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.view_graph()"
   ]
  },
  {
=======
>>>>>>> 860475dd5119768efc22c4f19be958bcce59e9a0
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply orbit file"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 66,
=======
   "execution_count": 21,
>>>>>>> 860475dd5119768efc22c4f19be958bcce59e9a0
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Apply-Orbit-File'\n",
    "\n",
    "node_id = 'Apply-Orbit-File-S' \n",
    "\n",
    "source_node_id = source_slave_orbit\n",
    "\n",
    "parameters = ellip_snap_helpers.get_operator_default_parameters(operator)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 67,
=======
   "execution_count": 22,
>>>>>>> 860475dd5119768efc22c4f19be958bcce59e9a0
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.add_node(node_id, operator, parameters, source_node_id)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 68,
=======
   "execution_count": 23,
>>>>>>> 860475dd5119768efc22c4f19be958bcce59e9a0
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Apply-Orbit-File'\n",
    "\n",
    "node_id = 'Apply-Orbit-File-M' \n",
    "\n",
    "source_node_id = source_master_orbit"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 69,
=======
   "execution_count": 24,
>>>>>>> 860475dd5119768efc22c4f19be958bcce59e9a0
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.add_node(node_id, operator, parameters, source_node_id)"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<graph>\n",
      "  <version>1.0</version>\n",
      "  <node id=\"Read-S(0)\">\n",
      "    <operator>Read</operator>\n",
      "    <sources/>\n",
      "    <parameters class=\"com.bc.ceres.binding.dom.XppDomElement\">\n",
      "      <formatName/>\n",
      "      <file>/workspace/data/S1A_IW_GRDH_1SDV_20181005T214239_20181005T214304_024006_029F71_16D6.zip</file>\n",
      "    </parameters>\n",
      "  </node>\n",
      "  <node id=\"Read-S(1)\">\n",
      "    <operator>Read</operator>\n",
      "    <sources/>\n",
      "    <parameters class=\"com.bc.ceres.binding.dom.XppDomElement\">\n",
      "      <formatName/>\n",
      "      <file>/workspace/data/S1A_IW_GRDH_1SDV_20181005T214304_20181005T214335_024006_029F71_C8C4.zip</file>\n",
      "    </parameters>\n",
      "  </node>\n",
      "  <node id=\"SliceAssembly-S\">\n",
      "    <operator>SliceAssembly</operator>\n",
      "    <sources>\n",
      "      <sourceProduct refid=\"Read-S(0)\"/>\n",
      "      <sourceProduct.1 refid=\"Read-S(1)\"/>\n",
      "    </sources>\n",
      "    <parameters class=\"com.bc.ceres.binding.dom.XppDomElement\">\n",
      "      <selectedPolarisations>VV</selectedPolarisations>\n",
      "    </parameters>\n",
      "  </node>\n",
      "  <node id=\"Read-M(0)\">\n",
      "    <operator>Read</operator>\n",
      "    <sources/>\n",
      "    <parameters class=\"com.bc.ceres.binding.dom.XppDomElement\">\n",
      "      <formatName/>\n",
      "      <file>/workspace/data/S1A_IW_GRDH_1SDV_20180607T214243_20180607T214308_022256_026888_8C77.zip</file>\n",
      "    </parameters>\n",
      "  </node>\n",
      "  <node id=\"Read-M(1)\">\n",
      "    <operator>Read</operator>\n",
      "    <sources/>\n",
      "    <parameters class=\"com.bc.ceres.binding.dom.XppDomElement\">\n",
      "      <formatName/>\n",
      "      <file>/workspace/data/S1A_IW_GRDH_1SDV_20180607T214218_20180607T214243_022256_026888_C1E1.zip</file>\n",
      "    </parameters>\n",
      "  </node>\n",
      "  <node id=\"SliceAssembly-M\">\n",
      "    <operator>SliceAssembly</operator>\n",
      "    <sources>\n",
      "      <sourceProduct refid=\"Read-M(0)\"/>\n",
      "      <sourceProduct.1 refid=\"Read-M(1)\"/>\n",
      "    </sources>\n",
      "    <parameters class=\"com.bc.ceres.binding.dom.XppDomElement\">\n",
      "      <selectedPolarisations>VV</selectedPolarisations>\n",
      "    </parameters>\n",
      "  </node>\n",
      "  <node id=\"Apply-Orbit-File-S\">\n",
      "    <operator>Apply-Orbit-File</operator>\n",
      "    <sources>\n",
      "      <sourceProduct refid=\"SliceAssembly-S\"/>\n",
      "    </sources>\n",
      "    <parameters class=\"com.bc.ceres.binding.dom.XppDomElement\">\n",
      "      <polyDegree>3</polyDegree>\n",
      "      <orbitType>Sentinel Precise (Auto Download)</orbitType>\n",
      "      <continueOnFail>false</continueOnFail>\n",
      "    </parameters>\n",
      "  </node>\n",
      "  <node id=\"Apply-Orbit-File-M\">\n",
      "    <operator>Apply-Orbit-File</operator>\n",
      "    <sources>\n",
      "      <sourceProduct refid=\"SliceAssembly-M\"/>\n",
      "    </sources>\n",
      "    <parameters class=\"com.bc.ceres.binding.dom.XppDomElement\">\n",
      "      <polyDegree>3</polyDegree>\n",
      "      <orbitType>Sentinel Precise (Auto Download)</orbitType>\n",
      "      <continueOnFail>false</continueOnFail>\n",
      "    </parameters>\n",
      "  </node>\n",
      "</graph>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mygraph.view_graph()"
   ]
  },
  {
=======
>>>>>>> 860475dd5119768efc22c4f19be958bcce59e9a0
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Land/sea mask"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 71,
=======
   "execution_count": 25,
>>>>>>> 860475dd5119768efc22c4f19be958bcce59e9a0
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Land-Sea-Mask'\n",
    "\n",
    "node_id = 'Land-Sea-Mask-S' \n",
    "\n",
    "source_node_id = 'Apply-Orbit-File-S' \n",
    "\n",
    "parameters = ellip_snap_helpers.get_operator_default_parameters(operator)\n",
    "\n",
    "parameters['landMask'] = 'false'"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 72,
=======
   "execution_count": 26,
>>>>>>> 860475dd5119768efc22c4f19be958bcce59e9a0
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.add_node(node_id, operator, parameters, source_node_id)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 73,
=======
   "execution_count": 27,
>>>>>>> 860475dd5119768efc22c4f19be958bcce59e9a0
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Land-Sea-Mask'\n",
    "\n",
    "node_id = 'Land-Sea-Mask-M' \n",
    "\n",
    "source_node_id = 'Apply-Orbit-File-M' \n",
    "\n",
    "parameters = ellip_snap_helpers.get_operator_default_parameters(operator)\n",
    "\n",
    "parameters['landMask'] = 'false'"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 74,
=======
   "execution_count": 28,
>>>>>>> 860475dd5119768efc22c4f19be958bcce59e9a0
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.add_node(node_id, operator, parameters, source_node_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEM assisted coregistration"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 75,
=======
   "execution_count": 29,
>>>>>>> 860475dd5119768efc22c4f19be958bcce59e9a0
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'DEM-Assisted-Coregistration'\n",
    "\n",
    "node_id = 'DEM-Assisted-Coregistration' \n",
    "\n",
    "source_node_id = ['Land-Sea-Mask-S',\n",
    "                  'Land-Sea-Mask-M']\n",
    "\n",
    "parameters = ellip_snap_helpers.get_operator_default_parameters(operator)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 76,
=======
   "execution_count": 30,
>>>>>>> 860475dd5119768efc22c4f19be958bcce59e9a0
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.add_node(node_id, operator, parameters, source_node_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 77,
=======
   "execution_count": 31,
>>>>>>> 860475dd5119768efc22c4f19be958bcce59e9a0
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Subset'\n",
    "\n",
    "node_id = 'Subset' \n",
    "\n",
    "source_node_id = 'DEM-Assisted-Coregistration'\n",
    "\n",
    "parameters = ellip_snap_helpers.get_operator_default_parameters(operator)\n",
    "\n",
    "parameters = ellip_snap_helpers.get_operator_default_parameters(operator)\n",
    "\n",
<<<<<<< HEAD
    "#parameters['geoRegion'] = box(*bbox).wkt\n",
=======
>>>>>>> 860475dd5119768efc22c4f19be958bcce59e9a0
    "parameters['geoRegion'] = aoi_wkt['value']\n",
    "parameters['copyMetadata'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 78,
=======
   "execution_count": 32,
>>>>>>> 860475dd5119768efc22c4f19be958bcce59e9a0
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.add_node(node_id, operator, parameters, source_node_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sea Mask"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 79,
=======
   "execution_count": 33,
>>>>>>> 860475dd5119768efc22c4f19be958bcce59e9a0
   "metadata": {},
   "outputs": [],
   "source": [
    "#operator = 'Land-Sea-Mask'\n",
    "\n",
    "#node_id = 'Land-Sea-Mask' \n",
    "\n",
    "#source_node_id = 'DEM-Assisted-Coregistration'\n",
    "\n",
    "#parameters = ellip_snap_helpers.get_operator_default_parameters(operator)\n",
    "#parameters['landMask'] = 'false'\n",
    "#parameters"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 80,
=======
   "execution_count": 34,
>>>>>>> 860475dd5119768efc22c4f19be958bcce59e9a0
   "metadata": {},
   "outputs": [],
   "source": [
    "#mygraph.add_node(node_id, operator, parameters, source_node_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offset tracking"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 81,
=======
   "execution_count": 35,
>>>>>>> 860475dd5119768efc22c4f19be958bcce59e9a0
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Offset-tracking'\n",
    "\n",
    "node_id = 'Offset-tracking' \n",
    "\n",
    "#source_node_id = 'Land-Sea-Mask' \n",
    "source_node_id = 'Subset'\n",
    "\n",
    "parameters = ellip_snap_helpers.get_operator_default_parameters(operator)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 82,
=======
   "execution_count": 36,
>>>>>>> 860475dd5119768efc22c4f19be958bcce59e9a0
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters['maxVelocity'] = max_velocity['value']\n",
    "parameters['fillHoles'] = 'false'\n",
    "parameters['spatialAverage'] = 'false'\n",
    "parameters['averageBoxSize'] = '5'"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 83,
=======
   "execution_count": 37,
>>>>>>> 860475dd5119768efc22c4f19be958bcce59e9a0
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'averageBoxSize': '5',\n",
       " 'fillHoles': 'false',\n",
       " 'gridAzimuthSpacing': '40',\n",
       " 'gridRangeSpacing': '40',\n",
       " 'maxVelocity': '8',\n",
       " 'radius': '4',\n",
       " 'registrationOversampling': '16',\n",
       " 'registrationWindowHeight': '128',\n",
       " 'registrationWindowWidth': '128',\n",
       " 'resamplingType': 'BICUBIC_INTERPOLATION',\n",
       " 'roiVector': None,\n",
       " 'spatialAverage': 'false',\n",
       " 'xCorrThreshold': '0.1'}"
      ]
     },
<<<<<<< HEAD
     "execution_count": 83,
=======
     "execution_count": 37,
>>>>>>> 860475dd5119768efc22c4f19be958bcce59e9a0
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 84,
=======
   "execution_count": 38,
>>>>>>> 860475dd5119768efc22c4f19be958bcce59e9a0
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.add_node(node_id, operator, parameters, source_node_id)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 85,
=======
   "execution_count": 39,
>>>>>>> 860475dd5119768efc22c4f19be958bcce59e9a0
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Write'\n",
    "\n",
    "parameters = ellip_snap_helpers.get_operator_default_parameters(operator)\n",
    "parameters['file'] = output_name\n",
    "parameters['formatName'] = 'BEAM-DIMAP'\n",
    "\n",
    "node_id = 'Write-Offset'\n",
    "\n",
    "source_node_id = 'Offset-tracking'\n",
    "\n",
    "mygraph.add_node(node_id, operator, parameters, source_node_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terrain correction"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 86,
=======
   "execution_count": 40,
>>>>>>> 860475dd5119768efc22c4f19be958bcce59e9a0
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Terrain-Correction'\n",
    "\n",
    "source_node_id = 'Offset-tracking' \n",
    "\n",
    "parameters = ellip_snap_helpers.get_operator_default_parameters(operator)\n",
    "\n",
    "node_id = 'Terrain-Correction'\n",
    "\n",
    "mygraph.add_node(node_id, operator, parameters, source_node_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 87,
=======
   "execution_count": 41,
>>>>>>> 860475dd5119768efc22c4f19be958bcce59e9a0
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Write'\n",
    "\n",
    "parameters = ellip_snap_helpers.get_operator_default_parameters(operator)\n",
    "parameters['file'] = output_name\n",
    "parameters['formatName'] = 'GeoTIFF-BigTIFF'\n",
    "\n",
    "node_id = 'Write'\n",
    "\n",
    "source_node_id = 'Terrain-Correction'\n",
    "\n",
    "mygraph.add_node(node_id, operator, parameters, source_node_id)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 88,
=======
   "execution_count": 42,
>>>>>>> 860475dd5119768efc22c4f19be958bcce59e9a0
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<graph>\n",
      "  <version>1.0</version>\n",
      "  <node id=\"Read-S(0)\">\n",
      "    <operator>Read</operator>\n",
      "    <sources/>\n",
      "    <parameters class=\"com.bc.ceres.binding.dom.XppDomElement\">\n",
      "      <formatName/>\n",
      "      <file>/workspace/data/S1A_IW_GRDH_1SDV_20181005T214239_20181005T214304_024006_029F71_16D6.zip</file>\n",
      "    </parameters>\n",
      "  </node>\n",
      "  <node id=\"Read-S(1)\">\n",
      "    <operator>Read</operator>\n",
      "    <sources/>\n",
      "    <parameters class=\"com.bc.ceres.binding.dom.XppDomElement\">\n",
      "      <formatName/>\n",
      "      <file>/workspace/data/S1A_IW_GRDH_1SDV_20181005T214304_20181005T214335_024006_029F71_C8C4.zip</file>\n",
      "    </parameters>\n",
      "  </node>\n",
      "  <node id=\"SliceAssembly-S\">\n",
      "    <operator>SliceAssembly</operator>\n",
      "    <sources>\n",
      "      <sourceProduct refid=\"Read-S(0)\"/>\n",
      "      <sourceProduct.1 refid=\"Read-S(1)\"/>\n",
      "    </sources>\n",
      "    <parameters class=\"com.bc.ceres.binding.dom.XppDomElement\">\n",
      "      <selectedPolarisations>VV</selectedPolarisations>\n",
      "    </parameters>\n",
      "  </node>\n",
      "  <node id=\"Read-M(0)\">\n",
      "    <operator>Read</operator>\n",
      "    <sources/>\n",
      "    <parameters class=\"com.bc.ceres.binding.dom.XppDomElement\">\n",
      "      <formatName/>\n",
      "      <file>/workspace/data/S1A_IW_GRDH_1SDV_20180607T214243_20180607T214308_022256_026888_8C77.zip</file>\n",
      "    </parameters>\n",
      "  </node>\n",
      "  <node id=\"Read-M(1)\">\n",
      "    <operator>Read</operator>\n",
      "    <sources/>\n",
      "    <parameters class=\"com.bc.ceres.binding.dom.XppDomElement\">\n",
      "      <formatName/>\n",
      "      <file>/workspace/data/S1A_IW_GRDH_1SDV_20180607T214218_20180607T214243_022256_026888_C1E1.zip</file>\n",
      "    </parameters>\n",
      "  </node>\n",
      "  <node id=\"SliceAssembly-M\">\n",
      "    <operator>SliceAssembly</operator>\n",
      "    <sources>\n",
      "      <sourceProduct refid=\"Read-M(0)\"/>\n",
      "      <sourceProduct.1 refid=\"Read-M(1)\"/>\n",
      "    </sources>\n",
      "    <parameters class=\"com.bc.ceres.binding.dom.XppDomElement\">\n",
      "      <selectedPolarisations>VV</selectedPolarisations>\n",
      "    </parameters>\n",
      "  </node>\n",
      "  <node id=\"Apply-Orbit-File-S\">\n",
      "    <operator>Apply-Orbit-File</operator>\n",
      "    <sources>\n",
      "      <sourceProduct refid=\"SliceAssembly-S\"/>\n",
      "    </sources>\n",
      "    <parameters class=\"com.bc.ceres.binding.dom.XppDomElement\">\n",
      "      <polyDegree>3</polyDegree>\n",
      "      <orbitType>Sentinel Precise (Auto Download)</orbitType>\n",
      "      <continueOnFail>false</continueOnFail>\n",
      "    </parameters>\n",
      "  </node>\n",
      "  <node id=\"Apply-Orbit-File-M\">\n",
      "    <operator>Apply-Orbit-File</operator>\n",
      "    <sources>\n",
      "      <sourceProduct refid=\"SliceAssembly-M\"/>\n",
      "    </sources>\n",
      "    <parameters class=\"com.bc.ceres.binding.dom.XppDomElement\">\n",
      "      <polyDegree>3</polyDegree>\n",
      "      <orbitType>Sentinel Precise (Auto Download)</orbitType>\n",
      "      <continueOnFail>false</continueOnFail>\n",
      "    </parameters>\n",
      "  </node>\n",
      "  <node id=\"Land-Sea-Mask-S\">\n",
      "    <operator>Land-Sea-Mask</operator>\n",
      "    <sources>\n",
      "      <sourceProduct refid=\"Apply-Orbit-File-S\"/>\n",
      "    </sources>\n",
      "    <parameters class=\"com.bc.ceres.binding.dom.XppDomElement\">\n",
      "      <geometry/>\n",
      "      <sourceBandNames/>\n",
      "      <shorelineExtension>0</shorelineExtension>\n",
      "      <invertGeometry>false</invertGeometry>\n",
      "      <landMask>false</landMask>\n",
      "      <useSRTM>true</useSRTM>\n",
      "    </parameters>\n",
      "  </node>\n",
      "  <node id=\"Land-Sea-Mask-M\">\n",
      "    <operator>Land-Sea-Mask</operator>\n",
      "    <sources>\n",
      "      <sourceProduct refid=\"Apply-Orbit-File-M\"/>\n",
      "    </sources>\n",
      "    <parameters class=\"com.bc.ceres.binding.dom.XppDomElement\">\n",
      "      <geometry/>\n",
      "      <sourceBandNames/>\n",
      "      <shorelineExtension>0</shorelineExtension>\n",
      "      <invertGeometry>false</invertGeometry>\n",
      "      <landMask>false</landMask>\n",
      "      <useSRTM>true</useSRTM>\n",
      "    </parameters>\n",
      "  </node>\n",
      "  <node id=\"DEM-Assisted-Coregistration\">\n",
      "    <operator>DEM-Assisted-Coregistration</operator>\n",
      "    <sources>\n",
      "      <sourceProduct refid=\"Land-Sea-Mask-S\"/>\n",
      "      <sourceProduct.1 refid=\"Land-Sea-Mask-M\"/>\n",
      "    </sources>\n",
      "    <parameters class=\"com.bc.ceres.binding.dom.XppDomElement\">\n",
      "      <demName>SRTM 3Sec</demName>\n",
      "      <demResamplingMethod>BICUBIC_INTERPOLATION</demResamplingMethod>\n",
      "      <maskOutAreaWithoutElevation>true</maskOutAreaWithoutElevation>\n",
      "      <outputRangeAzimuthOffset>false</outputRangeAzimuthOffset>\n",
      "      <externalDEMNoDataValue>0</externalDEMNoDataValue>\n",
      "      <tileExtensionPercent>50</tileExtensionPercent>\n",
      "      <externalDEMFile/>\n",
      "      <resamplingType>BISINC_5_POINT_INTERPOLATION</resamplingType>\n",
      "    </parameters>\n",
      "  </node>\n",
      "  <node id=\"Subset\">\n",
      "    <operator>Subset</operator>\n",
      "    <sources>\n",
      "      <sourceProduct refid=\"DEM-Assisted-Coregistration\"/>\n",
      "    </sources>\n",
      "    <parameters class=\"com.bc.ceres.binding.dom.XppDomElement\">\n",
      "      <tiePointGridNames/>\n",
      "      <bandNames/>\n",
      "      <subSamplingY>1</subSamplingY>\n",
      "      <subSamplingX>1</subSamplingX>\n",
      "      <region/>\n",
      "      <copyMetadata>true</copyMetadata>\n",
      "      <fullSwath>false</fullSwath>\n",
<<<<<<< HEAD
      "      <geoRegion>POLYGON ((119.46 -0.8,119.46 -0.412,120.3 -0.412,120.3 -0.8,119.46 -0.8))</geoRegion>\n",
=======
      "      <geoRegion>POLYGON ((120.234 -1.823, 120.234 -0.5600000000000001, 119.52 -0.5600000000000001, 119.52 -1.823, 120.234 -1.823))</geoRegion>\n",
>>>>>>> 860475dd5119768efc22c4f19be958bcce59e9a0
      "    </parameters>\n",
      "  </node>\n",
      "  <node id=\"Offset-tracking\">\n",
      "    <operator>Offset-tracking</operator>\n",
      "    <sources>\n",
      "      <sourceProduct refid=\"Subset\"/>\n",
      "    </sources>\n",
      "    <parameters class=\"com.bc.ceres.binding.dom.XppDomElement\">\n",
      "      <maxVelocity>8</maxVelocity>\n",
      "      <roiVector/>\n",
      "      <resamplingType>BICUBIC_INTERPOLATION</resamplingType>\n",
      "      <registrationWindowHeight>128</registrationWindowHeight>\n",
      "      <averageBoxSize>5</averageBoxSize>\n",
      "      <spatialAverage>false</spatialAverage>\n",
      "      <radius>4</radius>\n",
      "      <fillHoles>false</fillHoles>\n",
      "      <registrationOversampling>16</registrationOversampling>\n",
      "      <gridAzimuthSpacing>40</gridAzimuthSpacing>\n",
      "      <gridRangeSpacing>40</gridRangeSpacing>\n",
<<<<<<< HEAD
      "      <averageBoxSize>5</averageBoxSize>\n",
=======
      "      <xCorrThreshold>0.1</xCorrThreshold>\n",
>>>>>>> 860475dd5119768efc22c4f19be958bcce59e9a0
      "      <registrationWindowWidth>128</registrationWindowWidth>\n",
      "    </parameters>\n",
      "  </node>\n",
      "  <node id=\"Write-Offset\">\n",
      "    <operator>Write</operator>\n",
      "    <sources>\n",
      "      <sourceProduct refid=\"Offset-tracking\"/>\n",
      "    </sources>\n",
      "    <parameters class=\"com.bc.ceres.binding.dom.XppDomElement\">\n",
      "      <deleteOutputOnFailure>true</deleteOutputOnFailure>\n",
      "      <clearCacheAfterRowWrite>false</clearCacheAfterRowWrite>\n",
      "      <formatName>BEAM-DIMAP</formatName>\n",
      "      <writeEntireTileRows>true</writeEntireTileRows>\n",
      "      <file>S1_OFFSET_TRACKING_20180607214218_20181005214304</file>\n",
      "    </parameters>\n",
      "  </node>\n",
      "  <node id=\"Terrain-Correction\">\n",
      "    <operator>Terrain-Correction</operator>\n",
      "    <sources>\n",
      "      <sourceProduct refid=\"Offset-tracking\"/>\n",
      "    </sources>\n",
      "    <parameters class=\"com.bc.ceres.binding.dom.XppDomElement\">\n",
      "      <applyRadiometricNormalization>false</applyRadiometricNormalization>\n",
      "      <saveSigmaNought>false</saveSigmaNought>\n",
      "      <externalDEMFile/>\n",
      "      <saveLocalIncidenceAngle>false</saveLocalIncidenceAngle>\n",
      "      <alignToStandardGrid>false</alignToStandardGrid>\n",
      "      <saveGammaNought>false</saveGammaNought>\n",
      "      <outputComplex>false</outputComplex>\n",
      "      <sourceBandNames/>\n",
      "      <saveIncidenceAngleFromEllipsoid>false</saveIncidenceAngleFromEllipsoid>\n",
      "      <saveProjectedLocalIncidenceAngle>false</saveProjectedLocalIncidenceAngle>\n",
      "      <externalDEMNoDataValue>0</externalDEMNoDataValue>\n",
      "      <mapProjection>WGS84(DD)</mapProjection>\n",
      "      <auxFile>Latest Auxiliary File</auxFile>\n",
      "      <saveDEM>false</saveDEM>\n",
      "      <pixelSpacingInDegree>0</pixelSpacingInDegree>\n",
      "      <incidenceAngleForSigma0>Use projected local incidence angle from DEM</incidenceAngleForSigma0>\n",
      "      <demResamplingMethod>BILINEAR_INTERPOLATION</demResamplingMethod>\n",
      "      <externalAuxFile/>\n",
      "      <saveLatLon>false</saveLatLon>\n",
      "      <saveSelectedSourceBand>true</saveSelectedSourceBand>\n",
      "      <nodataValueAtSea>true</nodataValueAtSea>\n",
      "      <demName>SRTM 3Sec</demName>\n",
      "      <standardGridOriginX>0</standardGridOriginX>\n",
      "      <standardGridOriginY>0</standardGridOriginY>\n",
      "      <pixelSpacingInMeter>0</pixelSpacingInMeter>\n",
      "      <incidenceAngleForGamma0>Use projected local incidence angle from DEM</incidenceAngleForGamma0>\n",
      "      <externalDEMApplyEGM>true</externalDEMApplyEGM>\n",
      "      <saveBetaNought>false</saveBetaNought>\n",
      "      <imgResamplingMethod>BILINEAR_INTERPOLATION</imgResamplingMethod>\n",
      "    </parameters>\n",
      "  </node>\n",
      "  <node id=\"Write\">\n",
      "    <operator>Write</operator>\n",
      "    <sources>\n",
      "      <sourceProduct refid=\"Terrain-Correction\"/>\n",
      "    </sources>\n",
      "    <parameters class=\"com.bc.ceres.binding.dom.XppDomElement\">\n",
      "      <deleteOutputOnFailure>true</deleteOutputOnFailure>\n",
      "      <clearCacheAfterRowWrite>false</clearCacheAfterRowWrite>\n",
      "      <formatName>GeoTIFF-BigTIFF</formatName>\n",
      "      <writeEntireTileRows>true</writeEntireTileRows>\n",
      "      <file>S1_OFFSET_TRACKING_20180607214218_20181005214304</file>\n",
      "    </parameters>\n",
      "  </node>\n",
      "</graph>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the graph\n",
      "Process PID: 16741\n",
      "Executing processing graph\n",
      "======\n",
      "Master: 05Oct2018\n",
      "Slave: 05Oct2018 prep baseline: 0.0 temp baseline: 0.0\n",
      "Slave: 07Jun2018 prep baseline: 16.406063 temp baseline: 120.000244\n",
      "\n",
      "======\n",
      "Master: 07Jun2018\n",
      "Slave: 05Oct2018 prep baseline: -14.690111 temp baseline: -120.000244\n",
      "Slave: 07Jun2018 prep baseline: 0.0 temp baseline: 0.0\n",
      "\n",
      "....10%....20%....30%....40%....50%....60%....70%....80%....90% done.\n",
      "INFO: org.esa.snap.core.gpf.operators.tooladapter.ToolAdapterIO: Initializing external tool adapters\n",
      "INFO: org.hsqldb.persist.Logger: dataFileCache open start\n",
      "-- org.jblas INFO Deleting /tmp/jblas5831040194789046101/libjblas.so\n",
      "-- org.jblas INFO Deleting /tmp/jblas5831040194789046101/libjblas_arch_flavor.so\n",
      "-- org.jblas INFO Deleting /tmp/jblas5831040194789046101\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "mygraph.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TODO*\n",
    "\n",
    "- write output of dem coreg and look \n",
    "- find and convert velocity.csv to N/S displacement, (the file is in  output_name + '_offset' + .data\n",
    "- create .properties or XML for all files \n",
    "- erase output_name + '_offset' .dim and output_name + '_offset' .data\n",
    "- add legend\n",
    "\n",
    "Then we'll\n",
    "\n",
    "- ciop-release\n",
    "- build \n",
    "- deploy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the Azimuth direction of the Satellite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#output_name = 'S1_OFFSET_TRACKING_20180607214218_20181005214304'\n",
    "xml = ET.parse(output_name + '.dim').getroot().find(\"Dataset_Sources/MDElem[@name='metadata']/MDElem[@name='Abstracted_Metadata']\")\n",
    "heading_ang = float(xml.find(\"MDATTR[@name='centre_heading']\").text)\n",
    "\n",
    "xml = ET.parse(output_name + '.dim').getroot().find(\"Dataset_Sources/MDElem[@name='metadata']/MDElem[@name='Abstracted_Metadata']\")\n",
    "height = int(xml.find(\"MDATTR[@name='num_output_lines']\").text)\n",
    "width = int(xml.find(\"MDATTR[@name='num_samples_per_line']\").text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Velocity.csv Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Velocity', 'geometry:Point', 'mst_lat:Double', 'mst_lon:Double', 'slv_lat:Double', 'slv_lon:Double', 'distance:Double', 'velocity:Double', 'heading:Double', 'range_shift:Double', 'azimuth_shift:Double', 'style_css:String']\n"
     ]
    }
   ],
   "source": [
    "lat=[]\n",
    "lon=[]\n",
    "range_shift=[]\n",
    "azi_shift=[]\n",
    "velocity=[]\n",
    "with open(output_name + '.data' + '/vector_data/Velocity.csv','r') as csvfile:\n",
    "    spamreader = csv.reader(csvfile,delimiter='\\t')\n",
    "    a = next(spamreader)\n",
    "    a = next(spamreader)\n",
    "    print a\n",
    "    for row in spamreader:\n",
    "        lon.append(row[3])\n",
    "        lat.append(row[2]) \n",
    "        range_shift.append(row[9]) \n",
    "        azi_shift.append(row[10]) \n",
    "        velocity.append(row[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Velocity.tiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = gdal.Open(output_name + '.tif')\n",
    "band = ds.GetRasterBand(1)\n",
    "vel_array = band.ReadAsArray()\n",
    "gt = ds.GetGeoTransform()\n",
    "proj = ds.GetProjection()\n",
    "[height, width] = vel_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8176, 11149)\n",
      "8176\n"
     ]
    }
   ],
   "source": [
    "print vel_array.shape\n",
    "print height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191.88626072333466"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heading_ang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build arrays : azimuth shift, range_shift and velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat=np.array(lat,dtype=float)\n",
    "lon=np.array(lon,dtype=float)\n",
    "range_shift=np.array(range_shift,dtype=float)\n",
    "azi_shift=np.array(azi_shift,dtype=float)\n",
    "velocity=np.array(velocity,dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert to N-S and E-W motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8176, 11149)\n",
      "(11149,)\n",
      "11149\n"
     ]
    }
   ],
   "source": [
    "lat_vec = np.linspace(gt[3], gt[3]+gt[5]*height, height)\n",
    "lon_vec = np.linspace(gt[0], gt[0]+gt[1]*width, width)\n",
    "print vel_array.shape\n",
    "print lon_vec.shape\n",
    "print width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns_shift = azi_shift*math.cos(heading_ang) - range_shift*math.sin(heading_ang)\n",
    "ew_shift = azi_shift*math.sin(heading_ang) + range_shift*math.cos(heading_ang)\n",
    "\n",
    "xx, yy = np.meshgrid(lon_vec, lat_vec)\n",
    "EW_shift = interpolate.griddata((lon, lat), ew_shift, (xx, yy))\n",
    "NS_shift = interpolate.griddata((lon, lat), ns_shift, (xx, yy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mask out Sea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "NS_shift_msk = np.where(vel_array != 0, NS_shift, 0)\n",
    "EW_shift_msk = np.where(vel_array != 0, EW_shift, 0)\n",
    "vel_array_msk = np.where(vel_array != 0, vel_array, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mask out disp > 50 m "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "NS_shift_msk = np.where(np.abs(NS_shift_msk) < 50, NS_shift_msk, 0)\n",
    "EW_shift_msk = np.where(np.abs(EW_shift_msk) < 50, EW_shift_msk, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save as Geotiff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### EW displacement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = gdal.GetDriverByName(\"GTiff\")\n",
    "outdata = driver.Create('SNAP_displacement_EW.tif', width, height, 1, gdal.GDT_Float64)\n",
    "geotransform = gt\n",
    "outdata.SetGeoTransform(geotransform)##sets same geotransform as input\n",
    "srs = osr.SpatialReference()            # establish encoding\n",
    "srs.ImportFromEPSG(4326)                # WGS84 lat/long\n",
    "outdata.SetProjection(srs.ExportToWkt()) # export coords to file\n",
    "outdata.GetRasterBand(1).WriteArray(EW_shift_msk)\n",
    "outdata.GetRasterBand(1).SetNoDataValue(0)##if you want these values transparent\n",
    "outdata.FlushCache() ##saves to disk!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SNAP_displacement_EW' + '.tif', 'rb') as f_in, gzip.open('SNAP_displacement_EW' + '.gz', 'wb') as f_out:\n",
    "    shutil.copyfileobj(f_in, f_out)\n",
    "    \n",
    "#os.remove(output_name + '.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### NS displacement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = gdal.GetDriverByName(\"GTiff\")\n",
    "outdata = driver.Create('SNAP_displacement_NS.tif', width, height, 1, gdal.GDT_Float64)\n",
    "geotransform = gt\n",
    "outdata.SetGeoTransform(geotransform)##sets same geotransform as input\n",
    "srs = osr.SpatialReference()            # establish encoding\n",
    "srs.ImportFromEPSG(4326)                # WGS84 lat/long\n",
    "outdata.SetProjection(srs.ExportToWkt()) # export coords to file\n",
    "outdata.GetRasterBand(1).WriteArray(NS_shift_msk)\n",
    "outdata.GetRasterBand(1).SetNoDataValue(0)##if you want these values transparent\n",
    "outdata.FlushCache() ##saves to disk!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SNAP_displacement_NS' + '.tif', 'rb') as f_in, gzip.open('SNAP_displacement_NS' + '.gz', 'wb') as f_out:\n",
    "    shutil.copyfileobj(f_in, f_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Velocity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = gdal.GetDriverByName(\"GTiff\")\n",
    "outdata = driver.Create('SNAP_velocity.tif', width, height, 1, gdal.GDT_Float64)\n",
    "geotransform = gt\n",
    "outdata.SetGeoTransform(geotransform)##sets same geotransform as input\n",
    "srs = osr.SpatialReference()            # establish encoding\n",
    "srs.ImportFromEPSG(4326)                # WGS84 lat/long\n",
    "outdata.SetProjection(srs.ExportToWkt()) # export coords to file\n",
    "outdata.GetRasterBand(1).WriteArray(vel_array_msk)\n",
    "outdata.GetRasterBand(1).SetNoDataValue(0)##if you want these values transparent\n",
    "outdata.FlushCache() ##saves to disk!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SNAP_velocity' + '.tif', 'rb') as f_in, gzip.open('SNAP_velocity' + '.gz', 'wb') as f_out:\n",
    "    shutil.copyfileobj(f_in, f_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def eop_metadata(metadata):\n",
    "\n",
    "    opt = 'http://www.opengis.net/opt/2.1'\n",
    "    om  = 'http://www.opengis.net/om/2.0'\n",
    "    gml = 'http://www.opengis.net/gml/3.2'\n",
    "    eop = 'http://www.opengis.net/eop/2.1'\n",
    "    sar = 'http://www.opengis.net/sar/2.1'\n",
    "    \n",
    "    root = etree.Element('{%s}EarthObservation' % sar)\n",
    "\n",
    "    phenomenon_time = etree.SubElement(root, '{%s}phenomenonTime' % om)\n",
    "\n",
    "    time_period = etree.SubElement(phenomenon_time, '{%s}TimePeriod' % gml)\n",
    "\n",
    "    begin_position = etree.SubElement(time_period, '{%s}beginPosition'  % gml)\n",
    "\n",
    "    end_position = etree.SubElement(time_period, '{%s}endPosition'  % gml)\n",
    "\n",
    "    procedure = etree.SubElement(root, '{%s}procedure' % om)\n",
    "\n",
    "    earth_observation_equipment = etree.SubElement(procedure, '{%s}EarthObservationEquipment' % eop)\n",
    "\n",
    "    acquisition_parameters = etree.SubElement(earth_observation_equipment, '{%s}acquisitionParameters' % eop)\n",
    "\n",
    "    acquisition = etree.SubElement(acquisition_parameters, '{%s}Acquisition' % sar)\n",
    "\n",
    "    orbit_number = etree.SubElement(acquisition, '{%s}orbitNumber' % eop)\n",
    "\n",
    "    wrs_longitude_grid = etree.SubElement(acquisition, '{%s}wrsLongitudeGrid' % eop)\n",
    "\n",
    "    polarisation_channels = etree.SubElement(acquisition, '{%s}polarisationChannels' % eop)\n",
    "    \n",
    "    feature_of_interest = etree.SubElement(root, '{%s}featureOfInterest' % om)\n",
    "    footprint = etree.SubElement(feature_of_interest, '{%s}Footprint' % eop)\n",
    "    multi_extentOf = etree.SubElement(footprint, '{%s}multiExtentOf' % eop)\n",
    "    multi_surface = etree.SubElement(multi_extentOf, '{%s}MultiSurface' % gml)\n",
    "    surface_members = etree.SubElement(multi_surface, '{%s}surfaceMembers' % gml)\n",
    "    polygon = etree.SubElement(surface_members, '{%s}Polygon' % gml)    \n",
    "    exterior = etree.SubElement(polygon, '{%s}exterior' % gml)  \n",
    "    linear_ring = etree.SubElement(exterior, '{%s}LinearRing' % gml) \n",
    "    poslist = etree.SubElement(linear_ring, '{%s}posList' % gml) \n",
    "\n",
    "\n",
    "    result = etree.SubElement(root, '{%s}result' % om)\n",
    "    earth_observation_result = etree.SubElement(result, '{%s}EarthObservationResult' % opt)\n",
    "    cloud_cover_percentage = etree.SubElement(earth_observation_result, '{%s}cloudCoverPercentage' % opt)\n",
    "    \n",
    "    metadata_property = etree.SubElement(root, '{%s}metaDataProperty' % eop)\n",
    "    earth_observation_metadata = etree.SubElement(metadata_property, '{%s}EarthObservationMetaData' % eop)\n",
    "    identifier = etree.SubElement(earth_observation_metadata, '{%s}identifier' % eop)\n",
    "    \n",
    "    begin_position.text = metadata['startdate']\n",
    "    end_position.text = metadata['enddate']\n",
    "    \n",
    "    coords = np.asarray([t[::-1] for t in list(loads(metadata['wkt']).exterior.coords)]).tolist()\n",
    " \n",
    "    pos_list = ''\n",
    "    for elem in coords:\n",
    "        pos_list += ' '.join(str(e) for e in elem) + ' '   \n",
    "\n",
    "    poslist.attrib['count'] = str(len(coords))\n",
    "    poslist.text = pos_list\n",
    "    \n",
    "    \n",
    "    identifier.text = metadata['identifier'] \n",
    "\n",
    "    return etree.tostring(root, pretty_print=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the result WKT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = gdal.Open(output_name + '.tif')\n",
    "ulx, xres, xskew, uly, yskew, yres  = src.GetGeoTransform()\n",
    "\n",
    "max_x = ulx + (src.RasterXSize * xres)\n",
    "min_y = uly + (src.RasterYSize * yres)\n",
    "min_x = ulx \n",
    "max_y = uly\n",
    "\n",
    "source = osr.SpatialReference()\n",
    "source.ImportFromWkt(src.GetProjection())\n",
    "\n",
    "target = osr.SpatialReference()\n",
    "target.ImportFromEPSG(4326)\n",
    "\n",
    "transform = osr.CoordinateTransformation(source, target)\n",
    "\n",
    "result_wkt = box(transform.TransformPoint(min_x, min_y)[0],\n",
    "        transform.TransformPoint(min_x, min_y)[1],\n",
    "        transform.TransformPoint(max_x, max_y)[0],\n",
    "        transform.TransformPoint(max_x, max_y)[1]).wkt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the EOP XML metadata file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "eop_metadata = dict()\n",
    "\n",
    "eop_metadata['wkt'] = result_wkt\n",
    "eop_metadata['startdate'] = parser.parse(min(dates)).strftime('%Y-%m-%dT%H:%M:%S')\n",
    "eop_metadata['enddate'] = parser.parse(max(dates)).strftime('%Y-%m-%dT%H:%M:%S')\n",
    "\n",
    "eop_xml = output_name + '.xml'\n",
    "with open(eop_xml, 'wb') as file:\n",
    "    file.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "    file.write(json.dumps(eop_metadata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the properties file for the reproducibility notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for properties_file in ['result', 'stage-in']:\n",
    "\n",
    "    if properties_file == 'result':\n",
    "        title = 'Reproducibility notebook used for generating %s' % output_name\n",
    "    else: \n",
    "        title = 'Reproducibility stage-in notebook for Sentinel-1 data for generating %s' % output_name\n",
    "        \n",
    "    with open(properties_file + '.properties', 'wb') as file:\n",
    "        file.write('title=%s\\n' % title)\n",
    "        file.write('date=%s/%s\\n' % (parser.parse(min(dates)).strftime('%Y-%m-%dT%H:%M:%S'), parser.parse(max(dates)).strftime('%Y-%m-%dT%H:%M:%S')))      \n",
    "        file.write('geometry=%s' % (result_wkt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = []\n",
    "slave = []\n",
    "for items in input_identifiers:\n",
    "    for im in master_products:\n",
    "        if im.find(items) != -1:\n",
    "            master.append(items)\n",
    "    for im in slave_products:\n",
    "        if im.find(items) != -1:\n",
    "            slave.append(items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "for properties_file in ['SNAP_displacement_EW','SNAP_displacement_NS','SNAP_velocity']:\n",
    "    if properties_file == 'SNAP_displacement_EW':\n",
    "        title = 'SNAP Offset Tracking - EW displacement'\n",
    "        units = 'meters'\n",
    "    elif properties_file == 'SNAP_displacement_NS':\n",
    "        title = 'SNAP Offset Tracking - NS displacement'\n",
    "        units = 'meters'\n",
    "    elif properties_file == 'SNAP_velocity':\n",
    "        title = 'SNAP Offset Tracking - velocity' \n",
    "        units = 'meters/day'\n",
    "        \n",
    "    with open(properties_file + '.properties', 'wb') as file:\n",
    "        file.write('title=%s\\n' % title)\n",
    "        file.write('date=%s - %s\\n' % (parser.parse(min(dates)).strftime('%Y-%m-%dT%H:%M:%S'), parser.parse(max(dates)).strftime('%Y-%m-%dT%H:%M:%S')))      \n",
    "        file.write('unit=%s\\n' % units)\n",
    "        file.write('master product(s)=%s\\n' % master)\n",
    "        file.write('slave product(s)=%s\\n' % slave)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set color palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raster2rgb(raster_file, color_table, out_file_name, raster_band=1, discrete=True):\n",
    "    \n",
    "    #Reading the band\n",
    "    data_types ={'Byte':'B','UInt16':'H','Int16':'h','UInt32':'I','Int32':'i','Float32':'f','Float64':'d'}\n",
    "    #if exists(raster_file) is False:\n",
    "    #        raise Exception('[Errno 2] No such file or directory: \\'' + raster_file + '\\'')    \n",
    "    \n",
    "    dataset = gdal.Open(raster_file)\n",
    "    print discrete\n",
    "    if dataset == None:\n",
    "        raise Exception(\"Unable to read the data file\")\n",
    "        \n",
    "    geoTransform = dataset.GetGeoTransform()\n",
    "    proj = dataset.GetProjection()\n",
    "    \n",
    "    band = dataset.GetRasterBand(raster_band)\n",
    "    values = band.ReadRaster( 0, 0, band.XSize, band.YSize, band.XSize, band.YSize, band.DataType )\n",
    "    values = unpack(data_types[gdal.GetDataTypeName(band.DataType)]*band.XSize*band.YSize,values)\n",
    "    \n",
    "    #Preparing the color table and the output file\n",
    "    classification_values = color_table.keys()\n",
    "    classification_values.sort()\n",
    "    \n",
    "    base = Image.new( 'RGBA', (band.XSize,band.YSize) )\n",
    "    base_draw = ImageDraw.Draw(base)\n",
    "    alpha_mask = Image.new('L', (band.XSize,band.YSize), 255)\n",
    "    alpha_draw = ImageDraw.Draw(alpha_mask)\n",
    "    print color_table\n",
    "    #Reading the value and setting the output color for each pixel\n",
    "    for pos in range(len(values)):\n",
    "        y = pos/band.XSize\n",
    "        x = pos - y * band.XSize\n",
    "        for index in range(len(classification_values)):\n",
    "            if values[pos] <= classification_values[index] or index == len(classification_values)-1:\n",
    "                if discrete == True:\n",
    "                    if index == 0:\n",
    "                        index = 1\n",
    "                    elif index == len(classification_values)-1 and values[pos] >= classification_values[index]:\n",
    "                        index = index + 1\n",
    "                    color = color_table[classification_values[index-1]]\n",
    "                    base_draw.point((x,y), (color[0],color[1],color[2]))\n",
    "                    alpha_draw.point((x,y),color[3])\n",
    "                else:\n",
    "                    if index == 0:\n",
    "                        r = color_table[classification_values[0]][0]\n",
    "                        g = color_table[classification_values[0]][1]\n",
    "                        b = color_table[classification_values[0]][2]\n",
    "                        a = color_table[classification_values[0]][3]\n",
    "                    elif index == len(classification_values)-1 and values[pos] >= classification_values[index]:\n",
    "                        r = color_table[classification_values[index]][0]\n",
    "                        g = color_table[classification_values[index]][1]\n",
    "                        b = color_table[classification_values[index]][2]\n",
    "                        a = color_table[classification_values[index]][3]\n",
    "                    else:\n",
    "                        r = color_table[classification_values[index-1]][0] + (values[pos] - classification_values[index-1])*(color_table[classification_values[index]][0] - color_table[classification_values[index-1]][0])/(classification_values[index]-classification_values[index-1]) \n",
    "                        g = color_table[classification_values[index-1]][1] + (values[pos] - classification_values[index-1])*(color_table[classification_values[index]][1] - color_table[classification_values[index-1]][1])/(classification_values[index]-classification_values[index-1]) \n",
    "                        b = color_table[classification_values[index-1]][2] + (values[pos] - classification_values[index-1])*(color_table[classification_values[index]][2] - color_table[classification_values[index-1]][2])/(classification_values[index]-classification_values[index-1]) \n",
    "                        a = color_table[classification_values[index-1]][3] + (values[pos] - classification_values[index-1])*(color_table[classification_values[index]][3] - color_table[classification_values[index-1]][3])/(classification_values[index]-classification_values[index-1]) \n",
    "                        if values[pos] == 0:\n",
    "                            r = 0\n",
    "                            g = 0\n",
    "                            b = 0\n",
    "                            a = 255\n",
    "                    base_draw.point((x,y), (int(r),int(g),int(b)))\n",
    "                    alpha_draw.point((x,y),int(a))\n",
    "                    \n",
    "                break\n",
    "    #Adding transparency and saving the output image       \n",
    "    color_layer = Image.new('RGBA', base.size, (255, 255, 255, 0))\n",
    "    base = Image.composite(color_layer, base, alpha_mask)\n",
    "    base.save(out_file_name)\n",
    "\n",
    "    # update geolocation\n",
    "    ds_rgb = gdal.Open(out_file_name,1)\n",
    "    ds_rgb.SetGeoTransform(geoTransform)\n",
    "    ds_rgb.SetProjection(proj)\n",
    "    \n",
    "    ds_rgb.FlushCache()\n",
    "    \n",
    "    ds_rgb = None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def palette_disp(dataset):\n",
    "    palette = {}\n",
    "    cmap = np.round(cm.rainbow(np.linspace(0,1,5)))*255\n",
    "    cmap = cmap.astype(int)\n",
    "    for i in range(5):\n",
    "        cmap[i][3]=0\n",
    "    val = np.arange(np.floor(-2*(np.nanstd(dataset))-1), -np.floor(-2*(np.nanstd(dataset))-1)-2*np.floor(-2*np.nanstd(dataset)-1)/5 , -2*np.floor(-2*np.nanstd(dataset)-1)/4)\n",
    "    palette = {val[0]: cmap[0].tolist(), \n",
    "               val[1]: cmap[1].tolist(), \n",
    "               val[2]: cmap[2].tolist(), \n",
    "               val[3]: cmap[3].tolist(), \n",
    "               val[4]: cmap[4].tolist(),\n",
    "              } \n",
    "    return palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "{-1.5: [0, 255, 255, 0], 0.0: [255, 255, 255, 0], 3.0: [255, 0, 0, 0], -3.0: [0, 0, 255, 0], 1.5: [255, 255, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "ew_palette = palette_disp(EW_shift_msk)\n",
    "raster2rgb('SNAP_displacement_EW.tif',\n",
    "           ew_palette,\n",
    "           'SNAP_displacement_EW.rgb.tif',\n",
    "           raster_band=1,\n",
    "           discrete=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "{-1.5: [0, 255, 255, 0], 0.0: [255, 255, 255, 0], 3.0: [255, 0, 0, 0], -3.0: [0, 0, 255, 0], 1.5: [255, 255, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "ns_palette = palette_disp(NS_shift_msk)\n",
    "raster2rgb('SNAP_displacement_NS.tif',\n",
    "           ns_palette,\n",
    "           'SNAP_displacement_NS.rgb.tif',\n",
    "           raster_band=1,\n",
    "           discrete=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def palette_vel(dataset):\n",
    "    palette = {}\n",
    "    cmap = np.round(cm.rainbow(np.linspace(0,1,5)))*255\n",
    "    cmap = cmap.astype(int)\n",
    "    for i in range(5):\n",
    "        cmap[i][3]=0\n",
    "    val = np.arange(-np.floor(np.nanstd(dataset))-1, np.floor(np.nanstd(dataset))+2 , 2*(np.floor(np.nanstd(dataset))+1)/4)\n",
    "    palette = {val[0]: cmap[0].tolist(), \n",
    "               val[1]: cmap[1].tolist(), \n",
    "               val[2]: cmap[2].tolist(), \n",
    "               val[3]: cmap[3].tolist(), \n",
    "               val[4]: cmap[4].tolist(),\n",
    "              } \n",
    "    return palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "{0.0: [255, 255, 255, 0], 1.0: [255, 255, 0, 0], 2.0: [255, 0, 0, 0], -1.0: [0, 255, 255, 0], -2.0: [0, 0, 255, 0]}\n"
     ]
    }
   ],
   "source": [
    "vel_palette = palette_vel(velocity)\n",
    "raster2rgb('SNAP_velocity.tif',\n",
    "           vel_palette,\n",
    "           'SNAP_velocity.rgb.tif',\n",
    "           raster_band=1,\n",
    "           discrete=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def legend_dsp(dataset, output_name, obj):\n",
    "    leg = {}\n",
    "    cmap = np.round(cm.rainbow(np.linspace(0,1,5)))*255\n",
    "    cmap = cmap.astype(int)\n",
    "    for i in range(5):\n",
    "        cmap[i][3]=0\n",
    "    a = np.array([[np.floor(-2*(np.nanstd(dataset))-1), -np.floor(-2*(np.nanstd(dataset))-1)]])\n",
    "    plt.figure(figsize=(9, 2.5))\n",
    "    img = plt.imshow(a, cmap = 'rainbow')\n",
    "    plt.gca().set_visible(False)\n",
    "    cax = plt.axes([0.1, 0.2, 0.8, 0.6])\n",
    "    cb = plt.colorbar(orientation=\"horizontal\", cax=cax)\n",
    "    cb.ax.set_xlabel('%s' % obj)\n",
    "    plt.savefig(output_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend_dsp(EW_shift_msk, 'SNAP_displacement_EW.legend.png', 'EW displacement (m)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend_dsp(NS_shift_msk, 'SNAP_displacement_NS.legend.png', 'NS displacement (m)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def legend_vel(dataset, output_name, obj):\n",
    "    leg = {}\n",
    "    cmap = np.round(cm.rainbow(np.linspace(0,1,5)))*255\n",
    "    cmap = cmap.astype(int)\n",
    "    for i in range(5):\n",
    "        cmap[i][3]=0\n",
    "    a = np.array([[-np.floor(np.nanstd(dataset))-1, np.floor(np.nanstd(dataset))+1]])\n",
    "    plt.figure(figsize=(9, 2.5))\n",
    "    img = plt.imshow(a, cmap = 'rainbow')\n",
    "    plt.gca().set_visible(False)\n",
    "    cax = plt.axes([0.1, 0.2, 0.8, 0.6])\n",
    "    cb = plt.colorbar(orientation=\"horizontal\", cax=cax)\n",
    "    cb.ax.set_xlabel('%s' % obj)\n",
    "    plt.savefig(output_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend_vel(velocity, 'SNAP_velocity.legend.png', 'Velocity (m/day)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(output_name + '.dim') == True: \n",
    "    os.remove(output_name + '.dim')\n",
    "if os.path.isfile(output_name + '.tif') == True: \n",
    "    os.remove(output_name + '.tif')\n",
    "if os.path.isfile(output_name + '.xml') == True: \n",
    "    os.remove(output_name + '.xml')\n",
    "if os.path.isfile(output_name + '.data') == True: \n",
    "    shutil.rmtree(output_name + '.data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compress the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(output_name + '.tif', 'rb') as f_in, gzip.open(output_name + '.gz', 'wb') as f_out:\n",
    "#    shutil.copyfileobj(f_in, f_out)\n",
    "    \n",
    "#os.remove(output_name + '.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### License"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This work is licenced under a [Attribution-ShareAlike 4.0 International License (CC BY-SA 4.0)](http://creativecommons.org/licenses/by-sa/4.0/) \n",
    "\n",
    "YOU ARE FREE TO:\n",
    "\n",
    "* Share - copy and redistribute the material in any medium or format.\n",
    "* Adapt - remix, transform, and built upon the material for any purpose, even commercially.\n",
    "\n",
    "UNDER THE FOLLOWING TERMS:\n",
    "\n",
    "* Attribution - You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.\n",
    "* ShareAlike - If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
