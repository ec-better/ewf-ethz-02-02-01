{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Sentinel-1 feature tracking\n",
    "ethz-02-02-01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This application takes a pair of Sentinel-1 products and perform feature tracking using the run_dic package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"service\">Service definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "service = dict([('title', 'Sentinel-1 feature tracking'),\n",
    "                ('abstract', 'Sentinel-1 feature tracking'),\n",
    "                ('id', 'ewf-ethz-02-02-01')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_velocity = dict([('id', 'max_velocity'),\n",
    "                     ('value', '8'),\n",
    "                     ('title', 'Max velocity'),\n",
    "                     ('abstract', 'Max velocity (m/day)')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi = dict([('id', 'area_of_interest'),\n",
    "            ('value', 'POLYGON((-91.32114821675749 -1.141198173686936, -90.71737318778665 -1.009922494598408, -90.84942543017247 -0.5555272457029629, -91.40848642576378 -0.6637246974332075, -91.32114821675749 -1.141198173686936))'),\n",
    "            ('title', 'Area of interest in WKT'),\n",
    "            ('abstract', 'Area of interest in WKT')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem = dict([('id', 'dem'),\n",
    "            ('value', 'SRTM 3Sec'),\n",
    "            ('title', 'Area of interest in WKT'),\n",
    "            ('abstract', 'Area of interest in WKT'),\n",
    "            ('options', 'SRTM 3Sec,ACE30')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = dict([(\"id\", \"resolution\"),\n",
    "                   (\"title\", \"Spatial resolution\"),\n",
    "                   (\"value\", \"40\"),\n",
    "                   (\"abstract\", \"Spatial resolution in meters (10 or 40)\"),\n",
    "                   ('options', '10,40')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utm_zone = dict([('id', 'utm_zone'),\n",
    "                 ('title', 'UTM zone'),\n",
    "                 ('abstract', 'UTM zone'),\n",
    "                 ('value', 'EPSG:32715')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = dict([('id', 'window_size'),\n",
    "                    ('title', 'window_size'),\n",
    "                    ('abstract', 'window size in pixels'),\n",
    "                    ('value', '64')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampling_factor = dict([('id', 'oversampling_factor'),\n",
    "                            ('title', 'oversampling_factor'),\n",
    "                            ('abstract', 'oversampling factor'),\n",
    "                            ('value', '8')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_scale_limits = dict([('id', 'color_scale_limits'),\n",
    "                           ('title', 'color_scale_limits'),\n",
    "                           ('abstract', 'color_scale_limits'),\n",
    "                           ('value', '0,10')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"runtime\">Runtime parameter definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input identifiers**\n",
    "\n",
    "These are the Sentinel-1 product identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_identifiers = ('S1A_IW_GRDH_1SDV_20190824T002619_20190824T002648_028703_033FCF_961C',\n",
    "                     'S1A_IW_GRDH_1SDV_20190929T002620_20190929T002649_029228_0351FE_D742')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input references**\n",
    "\n",
    "These are the Sentinel-1 catalogue references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_references = ('https://catalog.terradue.com/sentinel1/search?uid=S1A_IW_GRDH_1SDV_20190824T002619_20190824T002648_028703_033FCF_961C',\n",
    "                    'https://catalog.terradue.com/sentinel1/search?uid=S1A_IW_GRDH_1SDV_20190929T002620_20190929T002649_029228_0351FE_D742')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Data path**\n",
    "\n",
    "This path defines where the data is staged-in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = '/workspace/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"workflow\">Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the packages required for processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append('/application/notebook/libexec/') \n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "import ellip_snap_helpers\n",
    "from ellip_snap_helpers import create_metadata\n",
    "import xml.etree.ElementTree as ET\n",
    "from snappy import jpy\n",
    "from snappy import ProductIO\n",
    "from snappy import GPF\n",
    "from snappy import HashMap\n",
    "\n",
    "import dateutil.parser as parser\n",
    "import geopandas as gpd\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from shapely.geos import ReadingError\n",
    "import gdal\n",
    "import time\n",
    "import exifread\n",
    "import lxml.etree as etree\n",
    "\n",
    "from shapely.wkt import loads\n",
    "from shapely.geometry import mapping\n",
    "from shapely.geometry import box\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sys.path.append('/opt/anaconda/bin/')\n",
    "\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "from osgeo.gdalconst import GA_ReadOnly\n",
    "from struct import unpack\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "\n",
    "import cioppy\n",
    "ciop = cioppy.Cioppy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if aoi['value'] == 'Full':\n",
    "    aoi_wkt = cascaded_union(search.geometry.values).wkt\n",
    "    min_lon, min_lat, max_lon, max_lat = cascaded_union(search.geometry.values).bounds\n",
    "\n",
    "else:\n",
    "\n",
    "    try:\n",
    "        aoi_wkt = loads(aoi['value']).wkt\n",
    "        min_lon, min_lat, max_lon, max_lat = loads(aoi['value']).bounds\n",
    "\n",
    "    except ReadingError:\n",
    "\n",
    "        aoi_wkt = box(*[float(i) for i in aoi['value'].split(',')]).wkt\n",
    "        min_lon, min_lat, max_lon, max_lat = [float(i) for i in aoi['value'].split(',')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print aoi_wkt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check if all the products have the same track number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_TR = [None]*len(input_references)\n",
    "\n",
    "for index,product_ref in enumerate(input_references):\n",
    "    \n",
    "    result_prod = ciop.search(end_point=product_ref,\n",
    "                              params=[],\n",
    "                              output_fields='startdate,track',\n",
    "                              model='EOP')\n",
    "    \n",
    "    product_TR[index] = result_prod[0]['track']\n",
    "    \n",
    "    if index==0:\n",
    "        \n",
    "        slave_date = result_prod[0]['startdate'][:10]\n",
    "    \n",
    "    elif result_prod[0]['startdate'][:10] > slave_date:\n",
    "    \n",
    "        slave_date = result_prod[0]['startdate'][:10]\n",
    "\n",
    "if not all(x == product_TR[0] for x in product_TR):\n",
    "\n",
    "    raise ValueError('Not all products pertain the same track!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slave_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "s1meta = \"manifest.safe\"\n",
    "\n",
    "slave_products = []\n",
    "master_products = []\n",
    "\n",
    "slave_prefix = []\n",
    "master_prefix = []\n",
    "\n",
    "dates = []\n",
    "\n",
    "for index, identifier in enumerate(input_identifiers):\n",
    "    \n",
    "    s1_zip_file = os.path.join(data_path, identifier + '.zip') \n",
    "    s1_meta_file = os.path.join(data_path, identifier, identifier + '.SAFE', 'manifest.safe')\n",
    "\n",
    "    if os.path.isfile(s1_zip_file):\n",
    "        s1prd = s1_zip_file\n",
    "    elif os.path.isfile(s1_meta_file):\n",
    "        s1prd = s1_meta_file\n",
    "\n",
    "    print identifier, s1prd\n",
    "    reader = ProductIO.getProductReader(\"SENTINEL-1\")\n",
    "    product = reader.readProductNodes(s1prd, None)\n",
    "    \n",
    "    \n",
    "    width = product.getSceneRasterWidth()\n",
    "    height = product.getSceneRasterHeight()\n",
    "    name = product.getName()\n",
    "    start_date = parser.parse(product.getStartTime().toString()).isoformat()\n",
    "    \n",
    "    dates.append(start_date[:19])\n",
    "\n",
    "    if start_date[:10] == slave_date:\n",
    "        \n",
    "            slave_products.append(s1prd)\n",
    "            print(\"\\nProduct: %s, %d x %d pixels of %s assigned as slave\" % (name, width, height, start_date))\n",
    "            slave_prefix.append(identifier.split('_')[-1]) \n",
    "            slave_data_take = identifier.split('_')[-2]\n",
    "    else:\n",
    "            master_products.append(s1prd)\n",
    "            print(\"\\nProduct: %s, %d x %d pixels of %s assigned as master\" % (name, width, height, start_date))\n",
    "            master_data_take = identifier.split('_')[-2]  \n",
    "            master_prefix.append(identifier.split('_')[-1]) \n",
    "\n",
    "                        \n",
    "output_name = 'S1_OFFSET_TRACKING_%s_%s' % (parser.parse(min(dates)).strftime('%Y%m%d%H%M%S'),\n",
    "                                                     parser.parse(max(dates)).strftime('%Y%m%d%H%M%S'))\n",
    "\n",
    "print(\"\\nco-registered OUTPUT Img name is %s\"%output_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph = ellip_snap_helpers.GraphProcessor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read and if need assemble the products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Read'\n",
    "\n",
    "node_id = 'Read'\n",
    "\n",
    "source_node_id = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(slave_products) > 1:\n",
    "  \n",
    "    slave_read_nodes = []\n",
    "    \n",
    "    # Read \n",
    "    for index, slave_identifier in enumerate(slave_products):\n",
    "        \n",
    "        operator = 'Read'\n",
    "        \n",
    "        parameters = ellip_snap_helpers.get_operator_default_parameters(operator)\n",
    "        \n",
    "        node_id = 'Read-S(%s)' % index\n",
    "        \n",
    "        source_node_id = ''\n",
    "        \n",
    "        parameters['file'] = slave_identifier\n",
    "                \n",
    "        mygraph.add_node(node_id, operator, parameters, source_node_id)\n",
    "    \n",
    "        slave_read_nodes.append(node_id)\n",
    "    \n",
    "    \n",
    "    source_nodes_id = slave_read_nodes\n",
    "        \n",
    "    operator = 'SliceAssembly'\n",
    "       \n",
    "    node_id = 'SliceAssembly-S'\n",
    "    \n",
    "    parameters = ellip_snap_helpers.get_operator_default_parameters(operator)\n",
    "    \n",
    "    #parameters['selectedPolarisations'] = polarisation['value']\n",
    "    \n",
    "    mygraph.add_node(node_id, operator, parameters, source_nodes_id)\n",
    "\n",
    "    source_slave_orbit = node_id\n",
    "    \n",
    "else:\n",
    "    \n",
    "    operator = 'Read'\n",
    "        \n",
    "    parameters = ellip_snap_helpers.get_operator_default_parameters(operator)\n",
    "        \n",
    "    node_id = 'Read-S'\n",
    "        \n",
    "    source_node_id = ''\n",
    "        \n",
    "    parameters['file'] = slave_products[0]\n",
    "        \n",
    "    mygraph.add_node(node_id, operator, parameters, source_node_id)\n",
    "    \n",
    "source_slave_orbit = node_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(master_products) > 1:\n",
    "      \n",
    "    master_read_nodes = []\n",
    "    \n",
    "    # Read \n",
    "    for index, master_identifer in enumerate(master_products):\n",
    "        \n",
    "        operator = 'Read'\n",
    "        \n",
    "        parameters = ellip_snap_helpers.get_operator_default_parameters(operator)\n",
    "        \n",
    "        node_id = 'Read-M(%s)' % index\n",
    "        \n",
    "        source_node_id = ''\n",
    "        \n",
    "        parameters['file'] = master_identifer\n",
    "        \n",
    "        mygraph.add_node(node_id, operator, parameters, source_node_id)\n",
    "    \n",
    "        master_read_nodes.append(node_id)\n",
    "    \n",
    "    \n",
    "    source_nodes_id = master_read_nodes\n",
    "        \n",
    "    operator = 'SliceAssembly'\n",
    "       \n",
    "    node_id = 'SliceAssembly-M'\n",
    "    \n",
    "    parameters = ellip_snap_helpers.get_operator_default_parameters(operator)\n",
    "    \n",
    "    #parameters['selectedPolarisations'] = polarisation['value']\n",
    "    \n",
    "    mygraph.add_node(node_id, operator, parameters, source_nodes_id)\n",
    "\n",
    "    source_master_orbit = node_id\n",
    "    \n",
    "else:\n",
    "    \n",
    "    operator = 'Read'\n",
    "        \n",
    "    parameters = ellip_snap_helpers.get_operator_default_parameters(operator)\n",
    "        \n",
    "    node_id = 'Read-M'\n",
    "        \n",
    "    source_node_id = ''\n",
    "        \n",
    "    parameters['file'] = master_products[0]\n",
    "        \n",
    "    mygraph.add_node(node_id, operator, parameters, source_node_id)\n",
    "    \n",
    "source_master_orbit = node_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply orbit file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Apply-Orbit-File'\n",
    "\n",
    "node_id = 'Apply-Orbit-File-S' \n",
    "\n",
    "source_node_id = source_slave_orbit\n",
    "\n",
    "parameters = ellip_snap_helpers.get_operator_default_parameters(operator)\n",
    "\n",
    "parameters['orbitType'] = 'Sentinel Restituted (Auto Download)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.add_node(node_id, operator, parameters, source_node_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Apply-Orbit-File'\n",
    "\n",
    "node_id = 'Apply-Orbit-File-M' \n",
    "\n",
    "source_node_id = source_master_orbit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.add_node(node_id, operator, parameters, source_node_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Land/sea mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Land-Sea-Mask'\n",
    "\n",
    "node_id = 'Land-Sea-Mask-S' \n",
    "\n",
    "source_node_id = 'Apply-Orbit-File-S' \n",
    "\n",
    "parameters = ellip_snap_helpers.get_operator_default_parameters(operator)\n",
    "\n",
    "parameters['landMask'] = 'false'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.add_node(node_id, operator, parameters, source_node_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Land-Sea-Mask'\n",
    "\n",
    "node_id = 'Land-Sea-Mask-M' \n",
    "\n",
    "source_node_id = 'Apply-Orbit-File-M' \n",
    "\n",
    "parameters = ellip_snap_helpers.get_operator_default_parameters(operator)\n",
    "\n",
    "parameters['landMask'] = 'false'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.add_node(node_id, operator, parameters, source_node_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEM assisted coregistration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'DEM-Assisted-Coregistration'\n",
    "\n",
    "node_id = 'DEM-Assisted-Coregistration' \n",
    "\n",
    "source_node_id = ['Land-Sea-Mask-S',\n",
    "                  'Land-Sea-Mask-M']\n",
    "\n",
    "parameters = ellip_snap_helpers.get_operator_default_parameters(operator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.add_node(node_id, operator, parameters, source_node_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Subset'\n",
    "\n",
    "node_id = 'Subset' \n",
    "\n",
    "source_node_id = 'DEM-Assisted-Coregistration'\n",
    "\n",
    "parameters = ellip_snap_helpers.get_operator_default_parameters(operator)\n",
    "\n",
    "parameters['geoRegion'] = aoi_wkt\n",
    "parameters['copyMetadata'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.add_node(node_id, operator, parameters, source_node_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terrain correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Terrain-Correction'\n",
    "\n",
    "source_node_id = 'Subset' \n",
    "\n",
    "parameters = ellip_snap_helpers.get_operator_default_parameters(operator)\n",
    "\n",
    "parameters['demName'] = dem['value']\n",
    "parameters['pixelSpacingInMeter'] = resolution['value']\n",
    "parameters['mapProjection'] = utm_zone['value']\n",
    "\n",
    "node_id = 'Terrain-Correction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.add_node(node_id, operator, parameters, source_node_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Write'\n",
    "\n",
    "parameters = ellip_snap_helpers.get_operator_default_parameters(operator)\n",
    "parameters['file'] = output_name\n",
    "parameters['formatName'] = 'GeoTIFF-BigTIFF'\n",
    "\n",
    "node_id = 'Write'\n",
    "\n",
    "source_node_id = 'Terrain-Correction'\n",
    "\n",
    "mygraph.add_node(node_id, operator, parameters, source_node_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print os.listdir(data_path)\n",
    "print os.listdir(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print os.listdir(data_path)\n",
    "print os.listdir(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate tiffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tif = '{}.tif'.format(output_name)\n",
    "f = open(output_tif, 'rb')\n",
    "tags = exifread.process_file(f)\n",
    "xml_data = tags['Image OwnerName'].values\n",
    "tree = ET.XML(xml_data)\n",
    "\n",
    "metadata = dict()\n",
    "\n",
    "for child in tree.find('Image_Interpretation'):\n",
    "    band_index = child.find('BAND_INDEX').text\n",
    "    name = child.find('BAND_NAME').text\n",
    "    metadata[band_index] = name\n",
    "    \n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = gdal.Open(output_tif)\n",
    "\n",
    "geo_transform = src.GetGeoTransform()\n",
    "projection = src.GetProjection()\n",
    "\n",
    "for band_number in range(1, src.RasterCount+1):\n",
    "     \n",
    "    band_data = src.GetRasterBand(band_number).ReadAsArray()\n",
    "    band_description = metadata[str(band_number-1)]\n",
    "    \n",
    "    #band_data = np.where(band_data==0, np.nan, band_data)\n",
    "    \n",
    "    print band_description\n",
    "\n",
    "    imgplot = plt.imshow(band_data)\n",
    "    plt.show()\n",
    "    \n",
    "    drv = gdal.GetDriverByName('GTiff')\n",
    "    ds = drv.Create('{}.tif'.format(band_description), band_data.shape[1], band_data.shape[0], 1, gdal.GDT_Float64)\n",
    "    ds.SetGeoTransform(geo_transform)\n",
    "    ds.SetProjection(projection)\n",
    "    ds.GetRasterBand(1).WriteArray(band_data)\n",
    "    ds.FlushCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print os.listdir(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of geotiffs produced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_list = list()\n",
    "slave_list = list()\n",
    "\n",
    "for element in metadata.values():\n",
    "    if 'mst' in element:\n",
    "        master_list.append(element)\n",
    "    if 'slv' in element:\n",
    "        slave_list.append(element)\n",
    "        \n",
    "print master_list\n",
    "print slave_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### writing the input_dic.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list = list()\n",
    "\n",
    "for idx, master_tif in enumerate(sorted(slave_list)):\n",
    "    \n",
    "    input_list.append('input_dic_{}.txt'.format(idx))\n",
    "\n",
    "    with open('input_dic_{}.txt'.format(idx), 'wb') as file:\n",
    "        file.write('{}.tif\\n'.format(master_tif))\n",
    "        file.write('{}.tif\\n'.format(sorted(master_list)[idx]))\n",
    "        file.write('{} {} {}\\n'.format(window_size['value'],oversampling_factor['value'], resolution['value']))\n",
    "        file.write('{} {}\\n'.format(color_scale_limits['value'].split(',')[0], color_scale_limits['value'].split(',')[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in input_list:\n",
    "    with open(file) as f:\n",
    "        print f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### running the package "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'LD_LIBRARY_PATH' not in os.environ.keys():\n",
    "    os.environ['LD_LIBRARY_PATH'] = '/opt/v94/runtime/glnxa64:/opt/v94/bin/glnxa64:/opt/v94/sys/os/glnxa64:/opt/v94/extern/bin/glnxa64'\n",
    "else:\n",
    "    os.environ['LD_LIBRARY_PATH'] = '/opt/v94/runtime/glnxa64:/opt/v94/bin/glnxa64:/opt/v94/sys/os/glnxa64:/opt/v94/extern/bin/glnxa64:' + os.environ['LD_LIBRARY_PATH']\n",
    "    \n",
    "import run_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print os.environ['LD_LIBRARY_PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(run_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_file in input_list:\n",
    "    \n",
    "    print input_file\n",
    "    \n",
    "    command = 'import run_dic; mr = run_dic.initialize(); mr.run_dic(\\\"{}\\\", nargout=0)'.format(input_file)\n",
    "\n",
    "    options = ['python', '-c', command]\n",
    "    \n",
    "    p = subprocess.Popen(options,\n",
    "                         stdout=subprocess.PIPE,\n",
    "                         stdin=subprocess.PIPE,\n",
    "                         stderr=subprocess.PIPE)\n",
    "\n",
    "    res, err = p.communicate()\n",
    "\n",
    "    if res:\n",
    "        print 'RESULTS:\\n'\n",
    "        for el in res.split('\\n'):\n",
    "            print el\n",
    "\n",
    "    if err:\n",
    "        print 'ERRORS:\\n'\n",
    "        for el in res.split('\\n'):\n",
    "            print el\n",
    "\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print os.listdir(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### deleting the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(output_tif)\n",
    "\n",
    "for tif in master_list:\n",
    "    os.remove('{}.tif'.format(tif))\n",
    "    \n",
    "for tif in slave_list:\n",
    "    os.remove('{}.tif'.format(tif))\n",
    "    \n",
    "for input_file in input_list:\n",
    "    os.remove(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print os.listdir(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for file in os.listdir(os.getcwd()):\n",
    "#   if '.tif' in file:\n",
    "#        print gdal.Info(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### adding geotransform and projection to the output geotiffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for file in os.listdir('./'):\n",
    "    if '.tif' in file:\n",
    "        print file\n",
    "        \n",
    "        \"\"\"old code that converts png into geotiff\"\"\"\n",
    "        #with rasterio.open(file, 'r') as ds:\n",
    "        #    arr = ds.read()\n",
    "        #drv = gdal.GetDriverByName('GTiff')\n",
    "        #ds = drv.Create('{}.tif'.format(os.path.splitext(os.path.basename(file))[0]), arr.shape[2], arr.shape[1], arr.shape[0], gdal.GDT_Byte)\n",
    "        \n",
    "        ds = gdal.Open(file, gdal.OF_UPDATE)\n",
    "        ds.SetGeoTransform(geo_transform)\n",
    "        ds.SetProjection(projection)\n",
    "        \n",
    "        #for band_number in range(arr.shape[0]):\n",
    "        #    ds.GetRasterBand(band_number+1).WriteArray(arr[band_number])\n",
    "        \n",
    "        ds.FlushCache()\n",
    "        \n",
    "        print gdal.Info(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trf = {'geo_transform' : geo_transform,\n",
    "        'projection' : projection}\n",
    "with open('geo_transform_projection.txt', 'wb') as file:\n",
    "    file.write(str(trf))\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('geo_transform_projection.txt') as f:\n",
    "    print f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print os.listdir(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = list()\n",
    "\n",
    "for file in os.listdir('.'):\n",
    "    if '.txt' in file:\n",
    "        output_file.append(file)\n",
    "\n",
    "output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = dict()\n",
    "\n",
    "try:\n",
    "    input_reference = input_references[0]\n",
    "    search0 = ciop.search(end_point=input_reference,\n",
    "                         params=dict(),\n",
    "                         output_fields='identifier, startdate, enddate, wkt',\n",
    "                         model='GeoTime')[0]\n",
    "    \n",
    "    input_reference = input_references[1]\n",
    "    search1 = ciop.search(end_point=input_reference,\n",
    "                         params=dict(),\n",
    "                         output_fields='identifier, startdate, enddate, wkt',\n",
    "                         model='GeoTime')[0]\n",
    "    \n",
    "    if search0['startdate'] > search1['startdate']:\n",
    "        master_date = search1['startdate']\n",
    "        slave_date = search0['startdate']\n",
    "    else:\n",
    "        master_date = search0['startdate']\n",
    "        slave_date = search1['startdate']\n",
    "    \n",
    "    metadata['startdate'] = master_date\n",
    "    metadata['enddate'] = slave_date\n",
    "    metadata['wkt'] = aoi_wkt\n",
    "    \n",
    "    print metadata\n",
    "    \n",
    "    for file in output_file:\n",
    "        print os.path.splitext(file)[0]\n",
    "\n",
    "        metadata['identifier'] = os.path.splitext(file)[0]\n",
    "        metadata['title'] = os.path.splitext(file)[0]\n",
    "        create_metadata(metadata, metadata['identifier'])\n",
    "\n",
    "except Exception as e:\n",
    "    print('ERROR: could not retrieve product metadata {}. {}'.format(input_reference, e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### License"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This work is licenced under a [Attribution-ShareAlike 4.0 International License (CC BY-SA 4.0)](http://creativecommons.org/licenses/by-sa/4.0/) \n",
    "\n",
    "YOU ARE FREE TO:\n",
    "\n",
    "* Share - copy and redistribute the material in any medium or format.\n",
    "* Adapt - remix, transform, and built upon the material for any purpose, even commercially.\n",
    "\n",
    "UNDER THE FOLLOWING TERMS:\n",
    "\n",
    "* Attribution - You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.\n",
    "* ShareAlike - If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
